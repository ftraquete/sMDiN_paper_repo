{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edad76a",
   "metadata": {},
   "source": [
    "# Sample Mass-Difference Networks in Metabolomics Data Analysis\n",
    "\n",
    "Notebook to support the study on the application of **Sample M**ass-**Di**fference **N**etworks as a highly specific competing form of pre-processing procedure for high-resolution metabolomics data.\n",
    "\n",
    "Mass-Difference Networks are focused into making networks from a list of masses. Each _m/z_ will represent a node. Nodes will be connected if the difference in their masses can be associated to a simple chemical reaction (enzymatic or non-enzymatic) that led to a change in the elemental composition of its metabolite.\n",
    "\n",
    "The set of mass differences used to build said networks are called a set of MDBs - Mass-Difference-based Building block.\n",
    "\n",
    "This is notebook `paper_sMDiNs_sMDiNsAnalysis.ipynb`\n",
    "\n",
    "\n",
    "## Organization of the Notebook\n",
    "\n",
    "- Loading up pre-processed and pre-treated dataset databases.\n",
    "- **Reading built MDiNs from Cytoscape and analyse some of their characteristics.**\n",
    "- **Subgraphing Sample MDiNs from MDiNs and analyse them.**\n",
    "- Join results from sMDiN analysis to the database of pre-processed and pre-treated datasets.\n",
    "\n",
    "Warning: Run this notebook after `paper_sMDiNs_database_prep.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8e5fe",
   "metadata": {},
   "source": [
    "#### Needed Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c9ed056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.ensemble as skensemble\n",
    "\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "# Metabolinks package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "\n",
    "# Python files in the repository\n",
    "import multianalysis as ma\n",
    "from elips import plot_confidence_ellipse\n",
    "\n",
    "# For multiprocessing sMDiN analysis of the HD dataset\n",
    "import smdins\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12da40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json for persistence\n",
    "\n",
    "import json\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88df4c",
   "metadata": {},
   "source": [
    "## Description of dataset records\n",
    "\n",
    "`datasets` is the global dict that holds all data sets. It is a **dict of dict's**.\n",
    "\n",
    "Each data set is **represented as a dict**.\n",
    "\n",
    "Each record has the following fields (keys):\n",
    "\n",
    "- `name`: the table/figure name of the data set\n",
    "- `source`: the biological source for each dataset\n",
    "- `mode`: the aquisition mode\n",
    "- `alignment`: the alignment used to generate the data matrix\n",
    "- `data`: the data matrix\n",
    "- `target`: the sample labels, possibly already integer encoded\n",
    "- `MDiN`: Mass-Difference Network\n",
    "- `<treatment name>`: transformed data matrix / network. These treatment names can be\n",
    "    - `original`: an alias to `data`\n",
    "    - `Ionly`: missing value imputed data by 1/5 of the minimum value in each sample in the dataset, only\n",
    "    - `P`: Pareto scaled data\n",
    "    - `NP`: Pareto scaled and normalized\n",
    "    - `NGP`: normalized, glog transformed and Pareto scaled\n",
    "    - `Ionly_RF`: missing value imputed data by random forests, only\n",
    "    - `P_RF`: Pareto scaled data\n",
    "    - `NP_RF`: Pareto scaled and normalized\n",
    "    - `NGP_RF`: normalized, glog transformed and Pareto scaled\n",
    "    - `IDT`: `NGP_RF` or `NGP` - Intensity-based Data pre-Treatment chosen as comparison based on which of the two performed better for each dataset and each statistical method\n",
    "    - `sMDiN`: Sample Mass-Difference Networks\n",
    "       \n",
    "- `<sMDiN analysis name>`: data matrix from nework analysis of MDiNs\n",
    "    - **`Degree`: degree analysis of each sMDiN**\n",
    "    - **`Betweenness`: betweenness centrality analysis of each sMDiN**\n",
    "    - **`Closeness`: closeness centrality of analysis of each sMDiN**\n",
    "    - **`MDBI`: analysis on the impact of each MDB (Mass-Difference based building-block) on building each sMDiN**\n",
    "    - **`GCD11`: Graphlet Correlation Distance of 11 different orbits (maximum of 4-node graphlets) between each sMDiN.**\n",
    "\n",
    "The keys of `datasets` may be shared with dicts holding records resulting from comparison analysis.\n",
    "\n",
    "Here are the keys (and respective names) of datasets used in this study:\n",
    "\n",
    "- GD_neg_global2 (GDg2-)\n",
    "- GD_pos_global2 (GDg2+)\n",
    "- GD_neg_class2 (GDc2-)\n",
    "- GD_pos_class2 (GDc2+)\n",
    "- YD (YD)\n",
    "- vitis_types (GD types)\n",
    "- HD (HD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b062b",
   "metadata": {},
   "source": [
    "### Reading datasets database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312cffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read benchmark datasets\n",
    "path = Path.cwd() / \"store_files\" / 'processed_data.json'\n",
    "storepath = Path.cwd() / \"store_files\" / 'processed_data.h5'\n",
    "with pd.HDFStore(storepath) as store:\n",
    "\n",
    "    with open(path, encoding='utf8') as read_file:\n",
    "        datasets = json.load(read_file)\n",
    "    \n",
    "    for dskey, dataset in datasets.items():\n",
    "        for key in dataset:\n",
    "            value = dataset[key]\n",
    "            if isinstance(value, str) and value.startswith(\"INSTORE\"):\n",
    "                storekey = value.split(\"_\", 1)[1]\n",
    "                dataset[key] = store[storekey]\n",
    "#datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52c205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomic masses - https://ciaaw.org/atomic-masses.htm\n",
    "#Isotopic abundances-https://ciaaw.org/isotopic-abundances.htm/https://www.degruyter.com/view/journals/pac/88/3/article-p293.xml\n",
    "# Isotopic abundances from Pure Appl. Chem. 2016; 88(3): 293–306,\n",
    "# Isotopic compositions of the elements 2013 (IUPAC Technical Report), doi: 10.1515/pac-2015-0503\n",
    "\n",
    "chemdict = {'H':(1.0078250322, 0.999844),\n",
    "            'C':(12.000000000, 0.988922),\n",
    "            'N':(14.003074004, 0.996337),\n",
    "            'O':(15.994914619, 0.9976206),\n",
    "            'Na':(22.98976928, 1.0),\n",
    "            'P':(30.973761998, 1.0),\n",
    "            'S':(31.972071174, 0.9504074),\n",
    "            'Cl':(34.9688527, 0.757647),\n",
    "            'F':(18.998403163, 1.0),\n",
    "            'C13':(13.003354835, 0.011078) # Carbon 13 isotope\n",
    "           } \n",
    "\n",
    "# electron mass from NIST http://physics.nist.gov/cgi-bin/cuu/Value?meu|search_for=electron+mass\n",
    "electron_mass = 0.000548579909065"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65385b1a",
   "metadata": {},
   "source": [
    "### Loading Mass-Difference Network of benchmark datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f95824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MDiN_functions as mdin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a227a",
   "metadata": {},
   "source": [
    "#### MDBs (Mass-Difference-based Building blocks) \n",
    "\n",
    "Building the **list of MDBs** to use when building the MDiNs.\n",
    "\n",
    "MDB - Mass-Difference-based Building blocks.\n",
    "\n",
    "The choice of this MDBs is then crucial in the network building process. Ideally, they should represent different 'simple' biochemical reactions that cover the most common and ubiquitous enzymatic and non-enzymatic reactions while also being a relatively small amount of reactions – a total of 15 were picked - and maintaining the metabolite formula charge neutrality. \n",
    "\n",
    "For example, to maintain neutrality, a phosphorylation would mean the overall addition of a PO3H – addition of a -PO3$^{2-}$ group + 2 H$^+$ (maintaining neutrality) to replace an H atom in a metabolite. All the MDBs chosen represent changes in metabolites of no more than 5 atoms and less than 80 Da (small size). Each MDB should represent a set of chemically known reactions and a change in every main element in metabolites (C, H, O, N, S and P) is represented by at least one of the MDBs. To fulfil these conditions, representative MDBs were searched using BRENDA (https://www.brenda-enzymes.org/). The groups chosen were the following:\n",
    "\n",
    "- CH2 (methylation) \n",
    "- O (oxygenation) \n",
    "- H2 (Hydrogenation)\n",
    "- O(N-H-) (Aminase): NH3(O-) - H2\n",
    "- PO3H (phosphorylation)\n",
    "- NH3(O-) (transaminases)\n",
    "- SO3 (sulphation)\n",
    "- CO (like formylation) \n",
    "- CO2 (carboxylation, decarboxylation)\n",
    "- CHOH (Hydroxymethylation) \n",
    "- NCH (formidoyltransferase)\n",
    "- CONH (carbamoyltransferase)\n",
    "- C2H2O (acetylation)\n",
    "- S (rare but an extra S reaction)\n",
    "- H2O\n",
    "\n",
    "There could be many other MDB representing other reactions that can also be included such as CN2H2 (amidinotransferases), COCH2COO (malonyl transferases), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5b36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemical Formula transformations (MDBs chosen)\n",
    "MDBs = ['H2','CH2','CO2','O','CHOH','NCH','O(N-H-)','S','CONH','PO3H','NH3(O-)','SO3','CO', 'C2H2O', 'H2O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0d662",
   "metadata": {},
   "source": [
    "### Build the Mass-Difference Networks in Cytoscape using MetaNetter 2.0\n",
    "\n",
    "To build the network in Cytoscape we need:\n",
    "\n",
    "1) A list of neutral masses (with masses as float in node attributes).\n",
    "\n",
    "2) A list of allowed transformations with specific mass differences - list of MDBs that we build above.\n",
    "\n",
    "The transformation files and the dataset files were built in `paper_sMDiNs_database_prep` and used in Cytoscape to build the MDiNs.\n",
    "\n",
    "Parameters: 1 ppm error allowed for edge establishment.\n",
    "\n",
    "The Yeast datasets already have the m/z 'buckets' that are already representing the neutral masses of the metabolites. To consider the neutral masses of the grapevine datasets, a simple transformation by adding or removing a proton (Hydrogen atom mass - electron mass), depending if the ionization mode is negative or positive, respectively, on the m/z peaks was made.\n",
    "\n",
    "Only one full network (for each benchmark dataset) is built. Then, subgraphs of them will be used to select every sample MDiN. This is the same as building an MDiN for each sample.\n",
    "\n",
    "The networks were exported in graphml format that networkX module can read.\n",
    "\n",
    "- Nodes have a standard number ID instead of the mass (stored as the attribute 'mass'). Other attributes stored are irrelevant. \n",
    "- Edges among the different attributes have a very useful attribute called 'Transformation' which stores which MDB of the list was used to establish the edge - will be used for MDB Impact analysis.\n",
    "- Finally, the graph is directed. Since reactions are bidireccional, they will be transformed to undirected graphs.\n",
    "\n",
    "Changes that will be made to the network:\n",
    "\n",
    "- Nodes will be identified by their masses.\n",
    "- Intensities of the node in each sample will be given later to store for each specific subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23a9d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MDiN based on data in GD_neg_global2 ...done!\n",
      "Reading MDiN based on data in GD_pos_global2 ...done!\n",
      "Reading MDiN based on data in GD_neg_class2 ...done!\n",
      "Reading MDiN based on data in GD_pos_class2 ...done!\n",
      "Reading MDiN based on data in YD ...done!\n",
      "Reading MDiN based on data in vitis_types ...done!\n",
      "Reading MDiN based on data in HD ...done!\n"
     ]
    }
   ],
   "source": [
    "# Read the MDiNs built using Cytoscape's MetaNetter\n",
    "for name, ds in datasets.items():\n",
    "    print(f'Reading MDiN based on data in {name}', end=' ...')\n",
    "    MDiN_temp = nx.read_graphml('mass_data/MassList' + name +'.graphml')\n",
    "    \n",
    "    # Making dicts for the new names\n",
    "    new_nodes = dict.fromkeys(MDiN_temp.nodes(),0)\n",
    "\n",
    "    for i,mz in nx.get_node_attributes(MDiN_temp,'mass').items(): # i is old name, mz is mass/new name\n",
    "        new_nodes[i] = mz\n",
    "\n",
    "    # Relabeling nodes\n",
    "    MDiN_temp = nx.relabel_nodes(MDiN_temp, mapping=new_nodes)\n",
    "    \n",
    "    ds['MDiN'] = MDiN_temp.to_undirected()\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "185f91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MDiNs\n",
    "#for name, ds in datasets.items():\n",
    "#    print(f'Building MDiN based on data in {name}', end=' ...')\n",
    "#    ds['MDiN'] = mdin.simple_MDiN(list(ds['data'].columns))\n",
    "#    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0261221",
   "metadata": {},
   "source": [
    "### MDiN characteristics\n",
    "\n",
    "Building a table with general characteristics about the 7 MDiNs built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b16bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_Chara = pd.DataFrame(columns=['# Nodes', '# Edges', 'Biggest Comp. Size', 'Connected Nodes', \n",
    "                                  'Diameter', 'Radius'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ccb9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ds in datasets.items():\n",
    "    Net_Chara.loc[name, '# Nodes'] = len(ds['MDiN'].nodes())\n",
    "    Net_Chara.loc[name, '# Edges'] = len(ds['MDiN'].edges())\n",
    "    \n",
    "    Main_component = ds['MDiN'].subgraph(list(sorted(nx.connected_components(ds['MDiN']), key=len, reverse=True)[0]))\n",
    "    Net_Chara.loc[name, 'Biggest Comp. Size'] = len(Main_component.nodes())\n",
    "    Net_Chara.loc[name, 'Diameter'] = nx.diameter(Main_component)\n",
    "    Net_Chara.loc[name, 'Radius'] = nx.radius(Main_component)\n",
    "    \n",
    "    isolated = 0\n",
    "    for node in ds['MDiN'].degree():\n",
    "        if node[1] == 0:\n",
    "            isolated = isolated + 1\n",
    "    Net_Chara.loc[name, 'Connected Nodes'] = (len(ds['MDiN'].nodes()) - isolated) / len(ds['MDiN'].nodes()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96de059d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Nodes</th>\n",
       "      <th># Edges</th>\n",
       "      <th>Biggest Comp. Size</th>\n",
       "      <th>Connected Nodes</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GD_neg_global2</th>\n",
       "      <td>3629</td>\n",
       "      <td>1005</td>\n",
       "      <td>183</td>\n",
       "      <td>32.433177</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_pos_global2</th>\n",
       "      <td>7026</td>\n",
       "      <td>6597</td>\n",
       "      <td>2482</td>\n",
       "      <td>55.735838</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_neg_class2</th>\n",
       "      <td>3026</td>\n",
       "      <td>718</td>\n",
       "      <td>145</td>\n",
       "      <td>29.312624</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_pos_class2</th>\n",
       "      <td>4565</td>\n",
       "      <td>3798</td>\n",
       "      <td>1472</td>\n",
       "      <td>52.968237</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YD</th>\n",
       "      <td>1893</td>\n",
       "      <td>810</td>\n",
       "      <td>275</td>\n",
       "      <td>35.60486</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitis_types</th>\n",
       "      <td>3026</td>\n",
       "      <td>718</td>\n",
       "      <td>145</td>\n",
       "      <td>29.312624</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD</th>\n",
       "      <td>12867</td>\n",
       "      <td>31008</td>\n",
       "      <td>7631</td>\n",
       "      <td>74.943654</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Nodes # Edges Biggest Comp. Size Connected Nodes Diameter  \\\n",
       "GD_neg_global2    3629    1005                183       32.433177       27   \n",
       "GD_pos_global2    7026    6597               2482       55.735838       49   \n",
       "GD_neg_class2     3026     718                145       29.312624       31   \n",
       "GD_pos_class2     4565    3798               1472       52.968237       45   \n",
       "YD                1893     810                275        35.60486       31   \n",
       "vitis_types       3026     718                145       29.312624       31   \n",
       "HD               12867   31008               7631       74.943654       63   \n",
       "\n",
       "               Radius  \n",
       "GD_neg_global2     14  \n",
       "GD_pos_global2     25  \n",
       "GD_neg_class2      16  \n",
       "GD_pos_class2      23  \n",
       "YD                 16  \n",
       "vitis_types        16  \n",
       "HD                 32  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net_Chara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c1e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O(N-H-)</th>\n",
       "      <th>NH3(O-)</th>\n",
       "      <th>H2</th>\n",
       "      <th>CH2</th>\n",
       "      <th>O</th>\n",
       "      <th>H2O</th>\n",
       "      <th>CO</th>\n",
       "      <th>NCH</th>\n",
       "      <th>CHOH</th>\n",
       "      <th>S</th>\n",
       "      <th>C2H2O</th>\n",
       "      <th>CONH</th>\n",
       "      <th>CO2</th>\n",
       "      <th>SO3</th>\n",
       "      <th>PO3H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GD_neg_global2</th>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>138</td>\n",
       "      <td>173</td>\n",
       "      <td>135</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_pos_global2</th>\n",
       "      <td>291</td>\n",
       "      <td>214</td>\n",
       "      <td>763</td>\n",
       "      <td>1229</td>\n",
       "      <td>821</td>\n",
       "      <td>735</td>\n",
       "      <td>612</td>\n",
       "      <td>289</td>\n",
       "      <td>98</td>\n",
       "      <td>118</td>\n",
       "      <td>544</td>\n",
       "      <td>261</td>\n",
       "      <td>386</td>\n",
       "      <td>121</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_neg_class2</th>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>91</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD_pos_class2</th>\n",
       "      <td>156</td>\n",
       "      <td>115</td>\n",
       "      <td>453</td>\n",
       "      <td>785</td>\n",
       "      <td>511</td>\n",
       "      <td>449</td>\n",
       "      <td>364</td>\n",
       "      <td>153</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>299</td>\n",
       "      <td>120</td>\n",
       "      <td>200</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YD</th>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>101</td>\n",
       "      <td>152</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitis_types</th>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>91</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HD</th>\n",
       "      <td>1878</td>\n",
       "      <td>1464</td>\n",
       "      <td>3196</td>\n",
       "      <td>4767</td>\n",
       "      <td>3832</td>\n",
       "      <td>2819</td>\n",
       "      <td>2317</td>\n",
       "      <td>2061</td>\n",
       "      <td>736</td>\n",
       "      <td>882</td>\n",
       "      <td>2521</td>\n",
       "      <td>1875</td>\n",
       "      <td>1902</td>\n",
       "      <td>448</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                O(N-H-)  NH3(O-)    H2   CH2     O   H2O    CO   NCH  CHOH  \\\n",
       "GD_neg_global2       50      120   138   173   135    58   111    34    36   \n",
       "GD_pos_global2      291      214   763  1229   821   735   612   289    98   \n",
       "GD_neg_class2        24       87   112   134    91    43    90     9    23   \n",
       "GD_pos_class2       156      115   453   785   511   449   364   153    41   \n",
       "YD                   38       32   101   152   100    96    78    27     6   \n",
       "vitis_types          24       87   112   134    91    43    90     9    23   \n",
       "HD                 1878     1464  3196  4767  3832  2819  2317  2061   736   \n",
       "\n",
       "                  S  C2H2O  CONH   CO2  SO3  PO3H  \n",
       "GD_neg_global2    8     39    24    61    9     9  \n",
       "GD_pos_global2  118    544   261   386  121   115  \n",
       "GD_neg_class2     4     25    15    46   10     5  \n",
       "GD_pos_class2    48    299   120   200   52    52  \n",
       "YD               13     62    19    39   11    36  \n",
       "vitis_types       4     25    15    46   10     5  \n",
       "HD              882   2521  1875  1902  448   310  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDB_counts = {}\n",
    "\n",
    "for name, ds in datasets.items():\n",
    "    MDB_counts[name] = dict.fromkeys(MDBs, 0) # MDBs from the transformation list\n",
    "    for i in ds['MDiN'].edges():\n",
    "        MDB_counts[name][ds['MDiN'].edges()[i]['Transformation']] = MDB_counts[name][\n",
    "            ds['MDiN'].edges()[i]['Transformation']] + 1\n",
    "        \n",
    "MDB_counts = pd.DataFrame.from_dict(MDB_counts)\n",
    "MDB_counts.reindex(['O(N-H-)','NH3(O-)','H2','CH2','O','H2O','CO','NCH','CHOH','S','C2H2O','CONH','CO2','SO3','PO3H']).T\n",
    "#MDB_counts.to_csv('TableS1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d598f0",
   "metadata": {},
   "source": [
    "For the **HD** dataset, due to its size in both node number and sample number, to accelerate posterior sMDiN network analysis, only nodes that have at least a degree of 1 (at least one edge) will be kept, discarding all uninformative isolated nodes from the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa4c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node_list = []\n",
    "for node in datasets['HD']['MDiN'].degree():\n",
    "    if node[1] > 0:\n",
    "        new_node_list.append(node[0])\n",
    "datasets['HD']['MDiN'] = datasets['HD']['MDiN'].subgraph(new_node_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517444b8",
   "metadata": {},
   "source": [
    "### Building and Analysing Sample MDiNs\n",
    "\n",
    "5 Analysis metrics of the Sample MDiNs were used:\n",
    "\n",
    "- Degree analysis\n",
    "- Betweenness - Betweenness centrality analysis\n",
    "- Closeness - Closeness centrality analysis\n",
    "- MDBI - Mass-Difference based building block Impact analysis\n",
    "- GCD11 - Graphlet Correlation Distance using 11 non-redundant graphlet orbits (maximum of 4-node graphlets) - GCD-11 analysis\n",
    "\n",
    "This analysis encompasses metrics that evaluate different aspects of the networs. \n",
    "\n",
    "Three measures of centrality: degree, centrality closeness, betweenness centrality commonly used to characterize networks. These metrics keep each node as a feature (no feature reduction) with its value for each sample being the respective metric value for each sample MDiN.\n",
    "\n",
    "The last two metrics greatly reduce the amount of features that will be considered by statistical methods to discriminate between the sample MDiNs (one to 15 and the other to 60).\n",
    "\n",
    "**MDB Impact** is a measure of the impact that each MDB had in establishing a sample MDiN. To that end, counts of the number of edges established due to each MDB are counted in each sample MDiN - each MDB represents a set of chemical reactions. To allow comparison between samples with different number of edges the counts in each sample MDiN are scaled by Pareto Scaling. This analysis was made to see if the relative importance of the MDBs in establishing the networks is characteristic of the class the sample belongs to.\n",
    "\n",
    "**GCD-11** is an analysis that focuses on the structure and topology of the networks. Briefly, this method considers and counts the number of times each node in the sMDiN is in one of 11 of the 15 possible orbits (4 are redundant - 3, 12, 13, 14) of 2 to 4-node graphlets. This builds a Graphlet Degree Vector for each node, building a dataframe with 11 orbits as columns. The spearman correlation between each pair of the 11 columns is calculated to generate a symmetric 11x11 matrix - the Graphlet Correlation Matrix (GCM) that represents, according to the authors, the signature of the network topology. The distance of the these matrices can be used to compare different networks - the Graphlet Correlation Distance. To use this signature of the topology of each network to discriminate the different sMDiNs, the correlations between each pair of orbits (total of 60) were extracted from the Graphlet Correlation Matrix from each sMDiN to be the features that will be compared against each other and used by the statistical methods. This analysis was made to see if the general topology of the sMDins is characteristic of the class the sample belongs to, knowing that this metric has been known to sucessfully discriminate between different networks.\n",
    "\n",
    "Useful papers for detailed explanations on GCD-11 and other related methodologies: \n",
    "- Yaveroğlu ÖN, Malod-Dognin N, Davis D, et al. Revealing the Hidden Language of Complex Networks. Sci Rep. 2014;4(1):4547. doi:10.1038/srep04547\n",
    "- Milenković T, Pržulj N. Uncovering biological network function via graphlet degree signatures. Cancer Inform. 2008;6:257-273. doi:10.4137/cin.s680 - some details on graphlet signatures\n",
    "- Tantardini M, Ieva F, Tajoli L, Piccardi C. Comparing methods for comparing networks. Sci Rep. 2019;9(1):1-19. doi:10.1038/s41598-019-53708-y - many different similar methods to GCD-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "791ac43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ds in datasets.items():\n",
    "    sMDiNs = {}\n",
    "    if name != 'HD':\n",
    "        for samp in ds['data'].index:\n",
    "            # Subgraphing sMDiN\n",
    "            sMDiNs[samp] = ds['MDiN'].subgraph(ds['data'].T[ds['data'].loc[samp,:].replace({np.nan:0}) != 0].index)\n",
    "\n",
    "            #Storing intensity of feature in sample on the nodes - Negative\n",
    "            intensity_attr = dict.fromkeys(sMDiNs[samp].nodes(),0)\n",
    "            #print(intensity_attr)\n",
    "            for i,m in nx.get_node_attributes(sMDiNs[samp],'mass').items():\n",
    "                intensity_attr[i] = {'intensity':ds['data'].loc[samp,m]}\n",
    "            nx.set_node_attributes(sMDiNs[samp],intensity_attr)\n",
    "    \n",
    "    else:\n",
    "        # For HD dataset, where the index of the 2D numerical matrix isn't the masses used for the MDiN.\n",
    "        for samp in ds['data'].index:\n",
    "            # Extracting the mass lists of each sample from the 2D numerical matrix\n",
    "            new_idx = ds['data'].T[ds['data'].loc[samp,:].replace({np.nan:0}) != 0].index\n",
    "            new_idx_final = []\n",
    "            for i in new_idx:\n",
    "                # Taking out a proton of the masses to 'neutralise' the mass.\n",
    "                new_idx_final.append(float(i.split('_')[0]) - chemdict['H'][0] + electron_mass)\n",
    "                \n",
    "            #Subgraphing sMDiN with the list of masses extracted\n",
    "            sMDiNs[samp] = ds['MDiN'].subgraph(new_idx_final)\n",
    "    \n",
    "    # Store all sMDiNs\n",
    "    ds['sMDiNs'] = sMDiNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c9035",
   "metadata": {},
   "source": [
    "Count number of graphlet orbits for GCD-11 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd88484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_orbits(GG):\n",
    "    \"\"\"Calculates the number of times each node of the network is in each possible (non-redundant) orbit in graphlets (maximum\n",
    "    4 nodes).\n",
    "    \n",
    "    Function is not very efficient, all nodes are passed, every graphlet is 'made' for each node present in it so it is made\n",
    "    multiple times.\n",
    "    \n",
    "       GG: networkx graph;\n",
    "    \n",
    "       returns: dict; dictionary (keys are the nodes) of dictionaries (keys are the orbits and values are the number of times)\n",
    "    \"\"\"\n",
    "    \n",
    "    node_orbits = {} # To store results\n",
    "\n",
    "    for i in GG.nodes():\n",
    "\n",
    "        node_orbits[i] = {} # To store results\n",
    "        orbits = node_orbits[i]\n",
    "\n",
    "        # 2 node graphlets - orbit 0\n",
    "        orbits['0'] = GG.degree(i)\n",
    "\n",
    "        # 3 node graphlets - orbit 1,2 (and 3 redundant)\n",
    "        node_neigh = list(GG.neighbors(i))\n",
    "\n",
    "        # orbit 1 and 4 and 6 and 8 and 9\n",
    "        n_orb = 0\n",
    "        n_orb4 = 0\n",
    "        n_orb6 = 0\n",
    "        n_orb8 = 0\n",
    "        n_orb9 = 0\n",
    "\n",
    "        # orbit 1\n",
    "        for j in node_neigh:\n",
    "            neigh_neigh = list(GG.neighbors(j)) # Neighbours of the neighbour j of i\n",
    "            neigh_neigh.remove(i) # Remove i since i is a neighbour of j\n",
    "            for common in nx.common_neighbors(GG, i, j):\n",
    "                neigh_neigh.remove(common) # Remove common neighbours of i and j\n",
    "            n_orb = n_orb + len(neigh_neigh)\n",
    "\n",
    "\n",
    "            # orbit 4 and 8\n",
    "            for n3 in neigh_neigh:\n",
    "                neigh_neigh_neigh = list(GG.neighbors(n3)) # Neighbours of the neighbour n3 of the neighbour j of i\n",
    "                #neigh_neigh_neigh.remove(j)\n",
    "                #if i in neigh_neigh_neigh:\n",
    "                    #neigh_neigh_neigh.remove(i)     \n",
    "                for common in nx.common_neighbors(GG, j, n3):\n",
    "                    if common in neigh_neigh_neigh:\n",
    "                        neigh_neigh_neigh.remove(common)\n",
    "\n",
    "                for common in nx.common_neighbors(GG, i, n3):\n",
    "                    if common in neigh_neigh_neigh:\n",
    "                        neigh_neigh_neigh.remove(common)\n",
    "                        # orbit 8\n",
    "                        if common != j:\n",
    "                            #print(i,j,n3,common)\n",
    "                            n_orb8 = n_orb8 + 1/2 # always goes in 2 directions so it will always pass like this\n",
    "\n",
    "                n_orb4 = n_orb4 + len(neigh_neigh_neigh)\n",
    "                # print(neigh_neigh_neigh)\n",
    "\n",
    "            # orbit 6 and 9\n",
    "            for u,v in itertools.combinations(neigh_neigh, 2):\n",
    "                if not GG.has_edge(u,v):\n",
    "                    n_orb6 = n_orb6 + 1\n",
    "                else:\n",
    "                    n_orb9 = n_orb9 + 1         \n",
    "\n",
    "        orbits['1'] = n_orb\n",
    "\n",
    "        # orbit 2 and 5\n",
    "        n_orb = 0\n",
    "        n_orb5 = 0\n",
    "        for u,v in itertools.combinations(node_neigh, 2):\n",
    "            if not GG.has_edge(u,v):\n",
    "                n_orb = n_orb + 1\n",
    "\n",
    "                # orbit 5\n",
    "                neigh_u = list(GG.neighbors(u))\n",
    "                neigh_u.remove(i)\n",
    "                for common in nx.common_neighbors(GG, i, u):\n",
    "                    neigh_u.remove(common)\n",
    "\n",
    "                neigh_v = list(GG.neighbors(v))\n",
    "                neigh_v.remove(i)\n",
    "                for common in nx.common_neighbors(GG, i, v):\n",
    "                    neigh_v.remove(common)\n",
    "\n",
    "                for common in nx.common_neighbors(GG, v, u):\n",
    "                    if common in neigh_u:\n",
    "                        neigh_u.remove(common)\n",
    "                    if common in neigh_v:\n",
    "                        neigh_v.remove(common) \n",
    "\n",
    "                n_orb5 = n_orb5 + len(neigh_u)\n",
    "                n_orb5 = n_orb5 + len(neigh_v)\n",
    "\n",
    "        orbits['2'] = n_orb\n",
    "\n",
    "        # 4 node graphlets - orbit 4,5,6,7,8,9,10,11 (and 12,13,14 redundant)\n",
    "\n",
    "        # orbit 4\n",
    "        orbits['4'] = n_orb4\n",
    "\n",
    "        # orbit 5\n",
    "        orbits['5'] = n_orb5\n",
    "\n",
    "        # orbit 6\n",
    "        orbits['6'] = n_orb6\n",
    "\n",
    "        # orbit 7 and 11\n",
    "        n_orb = 0\n",
    "        n_orb11 = 0\n",
    "        for u,v,j in itertools.combinations(node_neigh, 3):\n",
    "            n_edge = [GG.has_edge(a,b) for a,b in itertools.combinations((u,v,j), 2)]\n",
    "            #print(sum(n_edge))\n",
    "            if sum(n_edge) == 0:\n",
    "                n_orb = n_orb + 1\n",
    "            elif sum(n_edge) == 1:\n",
    "                n_orb11 = n_orb11 + 1\n",
    "\n",
    "        orbits['7'] = n_orb\n",
    "\n",
    "        # orbit 8\n",
    "        orbits['8'] = int(n_orb8)\n",
    "\n",
    "        # orbit 9\n",
    "        orbits['9'] = n_orb9\n",
    "\n",
    "        # orbit 10\n",
    "        n_orb = 0\n",
    "        for j in node_neigh:\n",
    "            neigh_neigh = list(GG.neighbors(j))\n",
    "            neigh_neigh.remove(i)\n",
    "            for u,v in itertools.combinations(neigh_neigh, 2):\n",
    "                if sum((GG.has_edge(i,u), GG.has_edge(i,v))) == 1:\n",
    "                    if not GG.has_edge(u,v):\n",
    "                        n_orb = n_orb + 1\n",
    "\n",
    "        orbits['10'] = n_orb\n",
    "\n",
    "        # orbit 11\n",
    "        orbits['11'] = n_orb11\n",
    "    \n",
    "    return node_orbits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5ad0a",
   "metadata": {},
   "source": [
    "### **Sample MDiN analysis** and results storage for 6 benchmark datasets (except HD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3df96be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing sample MDiNs from the data in GD_neg_global2 ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\francisco\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "Analysing sample MDiNs from the data in GD_pos_global2 ...done!\n",
      "Analysing sample MDiNs from the data in GD_neg_class2 ...done!\n",
      "Analysing sample MDiNs from the data in GD_pos_class2 ...done!\n",
      "Analysing sample MDiNs from the data in YD ...done!\n",
      "Analysing sample MDiNs from the data in vitis_types ...done!\n"
     ]
    }
   ],
   "source": [
    "for name, ds in datasets.items():\n",
    "    \n",
    "    if name == 'HD':\n",
    "        continue\n",
    "    print(f'Analysing sample MDiNs from the data in {name}', end=' ...')\n",
    "    \n",
    "    Deg = {}\n",
    "    Betw = {}\n",
    "    Close = {}\n",
    "    MDB_Impact = {}\n",
    "    GCD = {} \n",
    "    \n",
    "    for samp in ds['data'].index:\n",
    "        #print(name, samp)\n",
    "        k = None\n",
    "        \n",
    "        # Centrality measures\n",
    "        Deg[samp] = dict(ds['sMDiNs'][samp].degree())\n",
    "        Betw[samp] = nx.betweenness_centrality(ds['sMDiNs'][samp], k=k)\n",
    "        Close[samp] = nx.closeness_centrality(ds['sMDiNs'][samp])\n",
    "        \n",
    "        # MDB influence\n",
    "        MDB_Impact[samp] = dict.fromkeys(MDBs, 0) # MDBs from the transformation list\n",
    "        for i in ds['sMDiNs'][samp].edges():\n",
    "            MDB_Impact[samp][ds['sMDiNs'][samp].edges()[i]['Transformation']] = MDB_Impact[samp][\n",
    "                ds['sMDiNs'][samp].edges()[i]['Transformation']] + 1\n",
    "            \n",
    "        # GCD-11\n",
    "        # Corr_Mat\n",
    "        orbits_t = calculating_orbits(ds['sMDiNs'][samp]) # Calculating orbit number for each node\n",
    "        orbits_df = pd.DataFrame.from_dict(orbits_t).T # Transforming into a dataframe\n",
    "        \n",
    "        # Signature matrices\n",
    "        corrMat_ar = stats.spearmanr(orbits_df)[0] # Calculating spearman correlation to obtain 11x11 signature of the network - GCM\n",
    "        corrMat_tri = np.triu(corrMat_ar) # Both parts of the matrix are equal, so reducing the info to the upper triangle\n",
    "        \n",
    "        # Pulling the signature orbit n (u) - orbit m (v) correlations from the upper triangular matrix of the GCM\n",
    "        # Making the signature of the sample MDiN into a column of the dataset\n",
    "        samp_col = {}\n",
    "        orbits = [0,1,2,4,5,6,7,8,9,10,11]\n",
    "        for u in range(len(corrMat_tri)):\n",
    "            for v in range(u+1, len(corrMat_tri)):\n",
    "                samp_col[str(orbits[u]) + '-' + str(orbits[v])] = corrMat_tri[u,v]\n",
    "            GCD[samp] = samp_col\n",
    "    \n",
    "    # Centrality Measures\n",
    "    ds['Degree'] = pd.DataFrame.from_dict(Deg).replace({np.nan:0}).T\n",
    "    ds['Betweenness'] = pd.DataFrame.from_dict(Betw).replace({np.nan:0}).T\n",
    "    ds['Closeness'] = pd.DataFrame.from_dict(Close).replace({np.nan:0}).T\n",
    "    \n",
    "    # MDB Impact\n",
    "    ds['MDBI'] = pd.DataFrame.from_dict(MDB_Impact).replace({np.nan:0})\n",
    "    #ds['MDB_Imp'] = transf.pareto_scale(ds['MDB_Imp']).T.replace({np.nan:0})\n",
    "    ds['MDBI'] = (ds['MDBI']/ds['MDBI'].sum()*100).T\n",
    "    \n",
    "    # GCD-11\n",
    "    ds['GCD11'] = pd.DataFrame.from_dict(GCD).replace({np.nan:0}).T\n",
    "    \n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69c8cd",
   "metadata": {},
   "source": [
    "#### Sample MDiN analysis for the HD dataset using multiprocessing\n",
    "\n",
    "6 cores being used - Warning: see if the pc has at least 6 cores to process.\n",
    "\n",
    "Store results in results_HD list.\n",
    "\n",
    "Function in `smdins.py` called `HD_sMDiN_analysis` performs the 5 network analysis methods as in the cell before but stores them per sample instead of per metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebec88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5519c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 249/249 [13:33:49<00:00, 196.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# 6 cores\n",
    "with mp.Pool(6) as p:\n",
    "    results_HD = []\n",
    "    for i in tqdm(\n",
    "            p.imap(smdins.HD_sMDiN_analysis,\n",
    "                   [(samp, datasets['HD']['sMDiNs'][samp]) for samp in datasets['HD']['data'].index]),#, chunksize=5),\n",
    "            total=len([samp for samp in datasets['HD']['data'].index])\n",
    "        ):\n",
    "        results_HD.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a5a9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the results_HD list with a dict of the results for the 5 metrics for each sampleto add to the dataset database\n",
    "\n",
    "Deg = {}\n",
    "Betw = {}\n",
    "Close = {}\n",
    "MDB_Impact = {}\n",
    "GCD = {}\n",
    "\n",
    "for results in results_HD:\n",
    "    Deg[results['Name']] = results['Deg']\n",
    "    Betw[results['Name']] = results['Betweenness']\n",
    "    Close[results['Name']] = results['Closeness']\n",
    "    MDB_Impact[results['Name']] = results['MDBI']\n",
    "    GCD[results['Name']] = results['GCD']\n",
    "    \n",
    "# Centrality Measures\n",
    "datasets['HD']['Degree'] = pd.DataFrame.from_dict(Deg).replace({np.nan:0}).T\n",
    "datasets['HD']['Betweenness'] = pd.DataFrame.from_dict(Betw).replace({np.nan:0}).T\n",
    "datasets['HD']['Closeness'] = pd.DataFrame.from_dict(Close).replace({np.nan:0}).T\n",
    "\n",
    "# MDB Impact\n",
    "datasets['HD']['MDBI'] = pd.DataFrame.from_dict(MDB_Impact).replace({np.nan:0})\n",
    "#ds['MDBI'] = transf.pareto_scale(ds['MDBI']).T.replace({np.nan:0})\n",
    "datasets['HD']['MDBI'] = (datasets['HD']['MDBI']/datasets['HD']['MDBI'].sum()*100).T\n",
    "\n",
    "# GCD-11\n",
    "datasets['HD']['GCD11'] = pd.DataFrame.from_dict(GCD).replace({np.nan:0}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8206fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'alignment', 'mode', 'name', 'data', 'original', 'target', 'classes', 'Ionly', 'P', 'NP', 'NGP', 'Ionly_RF', 'P_RF', 'NP_RF', 'NGP_RF', 'IDT', 'Degree', 'Betw', 'Closeness', 'MDB_Imp', 'GCD11', 'MDiN', 'sMDiNs'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['HD'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c2b91",
   "metadata": {},
   "source": [
    "### Re-Generate json files and HDF Store including the data matrices obtained from sMDiN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d170dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure dir exists\n",
    "path = Path.cwd() / \"store_files\"\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "storepath = Path.cwd() / \"store_files\" / 'processed_data.h5'\n",
    "\n",
    "store = pd.HDFStore(storepath, complevel=9, complib=\"blosc:blosclz\")\n",
    "#pd.set_option('io.hdf.default_format','table')\n",
    "\n",
    "# keep json serializable values and store dataFrames in HDF store\n",
    "\n",
    "serializable = {}\n",
    "\n",
    "for dskey, dataset in datasets.items():\n",
    "    serializable[dskey] = {}\n",
    "    for key, value in dataset.items():\n",
    "        #print(dskey, key)\n",
    "        if isinstance(value, pd.DataFrame):\n",
    "            storekey = dskey + '_' + key\n",
    "            #print('-----', storekey)\n",
    "            store[storekey] = value\n",
    "            serializable[dskey][key] = f\"INSTORE_{storekey}\"\n",
    "        elif key in ('MDiN', 'sMDiNs'):\n",
    "            continue\n",
    "        else:\n",
    "            serializable[dskey][key] = value\n",
    "store.close()\n",
    "            \n",
    "\n",
    "path = path / 'processed_data.json'\n",
    "with open(path, \"w\", encoding='utf8') as write_file:\n",
    "    json.dump(serializable, write_file)\n",
    "\n",
    "#serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
